{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c67b3ff0fa04587dec508363308adaa3ceaf34",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4kjcC6QqywWl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import json\n",
    "import pydicom\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import glob \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e5764759e6a0a9b698b44645658f66873edd807",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yP0XLJx_x_6o"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../rsna-pneumonia-detection-challenge/'\n",
    "ROOT_DIR = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "576df4c47a23d08b1bdb384245e09aa69f88bbd3",
    "colab_type": "text",
    "id": "kdYzLq1zfKL4"
   },
   "source": [
    "### Install Matterport's Mask-RCNN model from github.\n",
    "See the [Matterport's implementation of Mask-RCNN](https://github.com/matterport/Mask_RCNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b37d22551d332f0f7b722cc7204eb614524b6c21",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KgllzLnDr7kF",
    "outputId": "6c978df7-2013-437e-acd1-5011048dfb53"
   },
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "3acbbbe055b6a409d3c50ae0f893acf51b5ae7ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "-KZXyWwhzOVU",
    "outputId": "2576cc17-7484-4311-ad72-3c5643dcb5bb"
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50089cc61791871cdf6a5c0037dc4f28b7b7d7cc",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FghMmiMjzOX2"
   },
   "outputs": [],
   "source": [
    "train_dicom_dir = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
    "test_dicom_dir = os.path.join(DATA_DIR, 'stage_1_test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5bb0c7810285bcb2eb44e01264e6502f4d6d65c"
   },
   "source": [
    "### Download COCO pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "283f120bd020612c0a52dddbb3dfe0d500516ee7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "!ls -lh mask_rcnn_coco.h5\n",
    "COCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "032cc5fe4baa051108106675e6ca4f4fdb2846ed",
    "colab_type": "text",
    "id": "gj-tvDvEaDiC"
   },
   "source": [
    "### Some setup functions and classes for Mask-RCNN\n",
    "\n",
    "- dicom_fps is a list of the dicom image path and filenames \n",
    "- image_annotions is a dictionary of the annotations keyed by the filenames\n",
    "- parsing the dataset returns a list of the image filenames and the annotations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "778cb19865d7cc63440491aef9202b71c61e8bb2",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ivqC4cnszOaM"
   },
   "outputs": [],
   "source": [
    "def get_dicom_fps(dicom_dir):\n",
    "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
    "    return list(set(dicom_fps))\n",
    "\n",
    "def parse_dataset(dicom_dir, anns): \n",
    "    image_fps = get_dicom_fps(dicom_dir)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows(): \n",
    "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
    "        image_annotations[fp].append(row)\n",
    "    return image_fps, image_annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "dfcffc4eaa94a41497717851dee9f702d8a2a73b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_SfzTa-1zOck",
    "outputId": "91ae8935-bccb-4b8e-9a7e-aa690f95fd9b"
   },
   "outputs": [],
   "source": [
    "class DetectorConfig(Config):\n",
    "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    Overrides values in the base Config class.\"\"\"\n",
    "    \n",
    "    # Give the configuration a recognizable name  \n",
    "    NAME = 'pneumonia'\n",
    "    \n",
    "    # Train on 1 GPU and 8 images per GPU.\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8 \n",
    "    \n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 256)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "    LEARNING_RATE = 0.0001\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    \n",
    "config = DetectorConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52bd3ffbdde0173a363055482d675da51c2aba99",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8EBVA1M60yAj"
   },
   "outputs": [],
   "source": [
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
    "        \n",
    "        # add images \n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations[fp]\n",
    "            self.add_image('pneumonia', image_id=i, path=fp, \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['Target'] == 1:\n",
    "                    x = int(a['x'])\n",
    "                    y = int(a['y'])\n",
    "                    w = int(a['width'])\n",
    "                    h = int(a['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cb852e262b69d348743767d675573368ab672c9",
    "colab_type": "text",
    "id": "9RlMo04ckd98"
   },
   "source": [
    "### Examine the annotation data, parse the dataset, and view dicom fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "793b1c6c6ba4e5f0d51e130080aa799f230b5ef6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EdhUEFDr0yDA",
    "outputId": "1715a5df-a577-41fd-bf20-f1a27aadb28c"
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_1_train_labels.csv'))\n",
    "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)\n",
    "\n",
    "# Original DICOM image size: 1024 x 1024\n",
    "ORIG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6175c72e73639e3190e127f67783988eadced9ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7jByVCZt-ZOC",
    "outputId": "f1aa267d-7530-4620-ffc5-2f7aa39083bb"
   },
   "outputs": [],
   "source": [
    "image_train_list = list(image_fps)\n",
    "sorted(image_train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5143c19dc22bc00d318a3b28cb7e13c7fbacc8a",
    "colab_type": "text",
    "id": "9KUvacUbgiEX"
   },
   "source": [
    "### Create and prepare the training dataset using the DetectorDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86c3333d4dfb8b7d00ce1f401693d0df4e6254e1",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jwMkhotP0yFf"
   },
   "outputs": [],
   "source": [
    "# prepare the training dataset\n",
    "dataset_train = DetectorDataset(\n",
    "    image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "313347d838fa8321a714858c8073f98c50c5be26",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K1TkWuGP0yHl"
   },
   "outputs": [],
   "source": [
    "# prepare the validation dataset\n",
    "dataset_val = DetectorDataset(\n",
    "    image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac5e11c89daeaa4e73af6a4967a4a375cddf284c",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "geTvh0sU1lJo"
   },
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n",
    "model.load_weights('../input/mask-rcnn-sample-starter-code/pneumonia20181002T0959/mask_rcnn_pneumonia_0015.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a9815f058a4a6deee1d99eea7071c07fb938a34",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp -r \"../input/mask-rcnn-sample-starter-code/pneumonia20181002T0959/\" \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "342b6008873fe7a6a0870a712ee47a87f0d2828d",
    "colab_type": "text",
    "id": "ustAIH78hZI_"
   },
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ab9d6086ce611a46f189c047956c43b29783e6d",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "STZnQTE61lME"
   },
   "outputs": [],
   "source": [
    "# Image augmentation (light but constant)\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.02)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        ),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.9, 1.1)),\n",
    "        iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e65d2cecb283f446f34cdde19b663a8a8e9590f",
    "colab_type": "text",
    "id": "M4kt7LKuc78e"
   },
   "source": [
    "### Now it's time to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f0029656b9ea98bfcc0ef8e6195e8d3cee238c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.STEPS_PER_EPOCH = 200\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0092fbe8598427a920e485d88a6048262ba77ce6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            epochs=15,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db5c10d3f7da099e5751a04a6e6d49819882ecd4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eraRlzgPmmIZ",
    "outputId": "de9e688c-ba4f-4b62-f842-dbcf00ce397c"
   },
   "outputs": [],
   "source": [
    "# select trained model \n",
    "dir_names = next(os.walk(model.model_dir))[1]\n",
    "key = config.NAME.lower()\n",
    "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
    "dir_names = sorted(dir_names)\n",
    "\n",
    "if not dir_names:\n",
    "    import errno\n",
    "    raise FileNotFoundError(\n",
    "        errno.ENOENT,\n",
    "        \"Could not find model directory under {}\".format(self.model_dir))\n",
    "    \n",
    "fps = []\n",
    "# Pick last directory\n",
    "for d in dir_names: \n",
    "    dir_name = os.path.join(model.model_dir, d)\n",
    "    # Find the last checkpoint\n",
    "    checkpoints = next(os.walk(dir_name))[2]\n",
    "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
    "    checkpoints = sorted(checkpoints)\n",
    "    if not checkpoints:\n",
    "        print('No weight files in {}'.format(dir_name))\n",
    "    else: \n",
    "        checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
    "        fps.append(checkpoint)\n",
    "\n",
    "model_path = sorted(fps)[-1]\n",
    "print('Found model {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52138636b2ae5bf444bba808518cd8313bde65cd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TgpT9AzC2Bgz",
    "outputId": "60f5a175-4666-497d-b4e8-0bdab39a92d0"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(DetectorConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0821ee0e454e86c5156209f11ff9b63b9abb4b70"
   },
   "source": [
    "### Model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb3da9feeaf2a85125b594027c7725afdfc1a2b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    x11, y11, w1, h1 = box1\n",
    "    x21, y21, w2, h2 = box2\n",
    "    assert w1 * h1 > 0\n",
    "    assert w2 * h2 > 0\n",
    "    x12, y12 = x11 + w1, y11 + h1\n",
    "    x22, y22 = x21 + w2, y21 + h2\n",
    "\n",
    "    area1, area2 = w1 * h1, w2 * h2\n",
    "    xi1, yi1, xi2, yi2 = max([x11, x21]), max([y11, y21]), min([x12, x22]), min([y12, y22])\n",
    "    \n",
    "    if xi2 <= xi1 or yi2 <= yi1:\n",
    "        return 0\n",
    "    else:\n",
    "        intersect = (xi2-xi1) * (yi2-yi1)\n",
    "        union = area1 + area2 - intersect\n",
    "        return intersect / union\n",
    "\n",
    "    \n",
    "def map_iou(boxes_true, boxes_pred, scores, thresholds=[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]):    \n",
    "    # According to the introduction, images with no ground truth bboxes will not be \n",
    "    # included in the map score unless there is a false positive detection (?)\n",
    "        \n",
    "    # return None if both are empty, don't count the image in final evaluation (?)\n",
    "    if len(boxes_true) == 0 and len(boxes_pred) == 0:\n",
    "        return None\n",
    "    \n",
    "    assert boxes_true.shape[1] == 4 or boxes_pred.shape[1] == 4\n",
    "    if len(boxes_pred):\n",
    "        assert len(scores) == len(boxes_pred), \"boxes_pred and scores should be same length\"\n",
    "        # sort boxes_pred by scores in decreasing order\n",
    "        boxes_pred = boxes_pred[np.argsort(scores)[::-1], :]\n",
    "    \n",
    "    map_total = 0\n",
    "    \n",
    "    # loop over thresholds\n",
    "    for t in thresholds:\n",
    "        matched_bt = set()\n",
    "        tp, fn = 0, 0\n",
    "        for i, bt in enumerate(boxes_true):\n",
    "            matched = False\n",
    "            for j, bp in enumerate(boxes_pred):\n",
    "                miou = iou(bt, bp)\n",
    "                if miou >= t and not matched and j not in matched_bt:\n",
    "                    matched = True\n",
    "                    tp += 1 # bt is matched for the first time, count as TP\n",
    "                    matched_bt.add(j)\n",
    "            if not matched:\n",
    "                fn += 1 # bt has no match, count as FN\n",
    "                \n",
    "        fp = len(boxes_pred) - len(matched_bt) # FP is the bp that not matched to any bt\n",
    "        m = tp / (tp + fn + fp)\n",
    "        map_total += m\n",
    "    \n",
    "    return map_total / len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d22bf2bae972a01f4568edf840e841e9bf3807d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "detector_eval = []; detector_scores = [];\n",
    "for i in range(1000):\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "        dataset_val, inference_config, i, use_mini_mask=False)\n",
    "    results = model.detect([image])[0]    \n",
    "    score = map_iou(gt_bbox, results['rois'], results['scores'])\n",
    "    if score != None:\n",
    "        detector_eval.append(score)\n",
    "        if score > 0:\n",
    "            detector_scores += [e for e in results['scores']]\n",
    "print(np.array(detector_eval).mean())\n",
    "best_conf = np.array(detector_scores).mean()\n",
    "print(best_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d343286bbefdb38626d264a9152e8fbc3341da99"
   },
   "source": [
    "### Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "186412199e25b98719f71cfe5e8869abcce516c4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1394
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "irheTbrW2Bl0",
    "outputId": "56041ad4-173d-45ab-af67-f54e8333511e"
   },
   "outputs": [],
   "source": [
    "# Show few example of ground truth vs. predictions on the validation dataset \n",
    "dataset = dataset_val\n",
    "\n",
    "for i in range(5):\n",
    "    image_id = random.choice(np.arange(1000))\n",
    "    \n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "        dataset_val, inference_config, image_id, use_mini_mask=False)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "    for i, box in enumerate(gt_bbox):\n",
    "        ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "        p = Polygon(((xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)),\n",
    "            fc=(1.0, 0.2, 0.2, 0.35), \n",
    "            ec=(1.0, 0.2, 0.2 ,0.95), lw=3, linestyle='--')\n",
    "        ax[0].add_patch(p)\n",
    "    ax[0].imshow(image)\n",
    "    \n",
    "    results = model.detect([image])[0]\n",
    "    \n",
    "    for i, box in enumerate(results['rois']):    \n",
    "        ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "        image[results['masks'][:,:,i]] = image[results['masks'][:,:,i]] * 0.5\n",
    "        p = Polygon(((xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)),\n",
    "            fc=(0.0, 0.5, 0.0, 0.35), \n",
    "            ec=(0.0, 0.5, 0.0 ,0.95), lw=3, linestyle='--')\n",
    "        ax[1].add_patch(p)\n",
    "    ax[1].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "164e18701a830bc6c42a791feea13549de37289b",
    "colab_type": "text",
    "id": "WcV1cL_aiSc4"
   },
   "source": [
    "### Final steps - Create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a5c0c6134408ddbf5a34496d7e9d7be5692e9a1",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "C6UWVrbM2Bob"
   },
   "outputs": [],
   "source": [
    "# Make predictions on test images, write out sample submission \n",
    "def predict(image_fps, filepath='submission.csv', min_conf=0.95): \n",
    "    \n",
    "    # assume square image\n",
    "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        for image_id in tqdm(image_fps): \n",
    "            ds = pydicom.read_file(image_id)\n",
    "            image = ds.pixel_array\n",
    "            # If grayscale. Convert to RGB for consistency.\n",
    "            if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "                image = np.stack((image,) * 3, -1) \n",
    "            image, window, scale, padding, crop = utils.resize_image(\n",
    "                image,\n",
    "                min_dim=config.IMAGE_MIN_DIM,\n",
    "                min_scale=config.IMAGE_MIN_SCALE,\n",
    "                max_dim=config.IMAGE_MAX_DIM,\n",
    "                mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "            patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "\n",
    "            results = model.detect([image])\n",
    "            r = results[0]\n",
    "\n",
    "            out_str = \"\"\n",
    "            out_str += patient_id \n",
    "            out_str += \",\"\n",
    "            assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
    "            if len(r['rois']) == 0: \n",
    "                pass\n",
    "            else: \n",
    "                num_instances = len(r['rois'])\n",
    "\n",
    "                for i in range(num_instances): \n",
    "                    if r['scores'][i] > min_conf: \n",
    "                        out_str += ' '\n",
    "                        out_str += str(round(r['scores'][i], 2))\n",
    "                        out_str += ' '\n",
    "\n",
    "                        # x1, y1, width, height \n",
    "                        x1 = r['rois'][i][1]\n",
    "                        y1 = r['rois'][i][0]\n",
    "                        width = r['rois'][i][3] - x1 \n",
    "                        height = r['rois'][i][2] - y1 \n",
    "                        bboxes_str = \"{} {} {} {}\".format(\n",
    "                            x1*resize_factor, y1*resize_factor, \n",
    "                            width*resize_factor, height*resize_factor)   \n",
    "                        #bboxes_str = \"{} {} {} {}\".format(x1, y1, width, height)\n",
    "                        out_str += bboxes_str\n",
    "\n",
    "            file.write(out_str+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1d572cb942f3e6c4244acfd2654082a58ce3f6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get filenames of test dataset DICOM images\n",
    "test_image_fps = get_dicom_fps(test_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0406e7f5aaa4867782c4f9c064f90bba386128e7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "C5cBpNka2Bsv",
    "outputId": "a2af9176-d9d6-49f6-f22a-5a1c455d144f"
   },
   "outputs": [],
   "source": [
    "submission = os.path.join(ROOT_DIR, 'submission.csv')\n",
    "predict(test_image_fps, filepath=submission, min_conf=best_conf)\n",
    "\n",
    "output = pd.read_csv(submission, names=['patientId', 'PredictionString'])\n",
    "output.to_csv('../output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97e0af4a0e49f445e96be756081d2c82de79c7cc",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lesson-3-rsna-pneumonia-detection-challenge-kaggle",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

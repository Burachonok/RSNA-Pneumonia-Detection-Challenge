{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c67b3ff0fa04587dec508363308adaa3ceaf34",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4kjcC6QqywWl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import json\n",
    "import pydicom\n",
    "import skimage.io\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import glob \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e5764759e6a0a9b698b44645658f66873edd807",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yP0XLJx_x_6o"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../rsna-pneumonia-detection-challenge/'\n",
    "ROOT_DIR = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "576df4c47a23d08b1bdb384245e09aa69f88bbd3",
    "colab_type": "text",
    "id": "kdYzLq1zfKL4"
   },
   "source": [
    "### Install Matterport's Mask-RCNN model from github.\n",
    "See the [Matterport's implementation of Mask-RCNN](https://github.com/matterport/Mask_RCNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b37d22551d332f0f7b722cc7204eb614524b6c21",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KgllzLnDr7kF",
    "outputId": "6c978df7-2013-437e-acd1-5011048dfb53"
   },
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "3acbbbe055b6a409d3c50ae0f893acf51b5ae7ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "-KZXyWwhzOVU",
    "outputId": "2576cc17-7484-4311-ad72-3c5643dcb5bb"
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50089cc61791871cdf6a5c0037dc4f28b7b7d7cc",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FghMmiMjzOX2"
   },
   "outputs": [],
   "source": [
    "train_dicom_dir = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
    "test_dicom_dir = os.path.join(DATA_DIR, 'stage_1_test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "032cc5fe4baa051108106675e6ca4f4fdb2846ed",
    "colab_type": "text",
    "id": "gj-tvDvEaDiC"
   },
   "source": [
    "### Some setup functions and classes for Mask-RCNN\n",
    "\n",
    "- dicom_fps is a list of the dicom image path and filenames \n",
    "- image_annotions is a dictionary of the annotations keyed by the filenames\n",
    "- parsing the dataset returns a list of the image filenames and the annotations dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "778cb19865d7cc63440491aef9202b71c61e8bb2",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ivqC4cnszOaM"
   },
   "outputs": [],
   "source": [
    "def get_dicom_fps(dicom_dir):\n",
    "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
    "    return list(set(dicom_fps))\n",
    "\n",
    "def parse_dataset(dicom_dir, anns): \n",
    "    image_fps = get_dicom_fps(dicom_dir)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows(): \n",
    "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
    "        image_annotations[fp].append(row)\n",
    "    return image_fps, image_annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "dfcffc4eaa94a41497717851dee9f702d8a2a73b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_SfzTa-1zOck",
    "outputId": "91ae8935-bccb-4b8e-9a7e-aa690f95fd9b"
   },
   "outputs": [],
   "source": [
    "class DetectorConfig(Config):\n",
    "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    Overrides values in the base Config class.\"\"\"\n",
    "    \n",
    "    # Give the configuration a recognizable name  \n",
    "    NAME = 'pneumonia'\n",
    "    \n",
    "    # Train on 1 GPU and 8 images per GPU.\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8 \n",
    "    \n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "    \n",
    "config = DetectorConfig()\n",
    "#config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52bd3ffbdde0173a363055482d675da51c2aba99",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8EBVA1M60yAj"
   },
   "outputs": [],
   "source": [
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, \n",
    "                 orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
    "        \n",
    "        # add images \n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations[fp]\n",
    "            self.add_image('pneumonia', image_id=i, path=fp, \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "        \n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        image = None\n",
    "        if fp.split('.')[-1] == 'dcm':\n",
    "            ds = pydicom.read_file(fp)\n",
    "            image = ds.pixel_array\n",
    "        if fp.split('.')[-1] == 'jpeg' or fp.split('.')[-1] == 'png':\n",
    "            image = skimage.io.imread(fp)\n",
    "            \n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) == 3:\n",
    "            if image.shape[2] > 3:\n",
    "                image = image[:,:,0]\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:                \n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['Target'] == 1:\n",
    "                    x = int(a['x'])\n",
    "                    y = int(a['y'])\n",
    "                    w = int(a['width'])\n",
    "                    h = int(a['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cb852e262b69d348743767d675573368ab672c9",
    "colab_type": "text",
    "id": "9RlMo04ckd98"
   },
   "source": [
    "### Examine the annotation data, parse the dataset, and view dicom fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "793b1c6c6ba4e5f0d51e130080aa799f230b5ef6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EdhUEFDr0yDA",
    "outputId": "1715a5df-a577-41fd-bf20-f1a27aadb28c"
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_1_train_labels.csv'))\n",
    "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)\n",
    "\n",
    "# Original DICOM image size: 1024 x 1024\n",
    "ORIG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6175c72e73639e3190e127f67783988eadced9ba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7jByVCZt-ZOC",
    "outputId": "f1aa267d-7530-4620-ffc5-2f7aa39083bb"
   },
   "outputs": [],
   "source": [
    "image_train_list = list(image_fps)\n",
    "sorted(image_train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5143c19dc22bc00d318a3b28cb7e13c7fbacc8a",
    "colab_type": "text",
    "id": "9KUvacUbgiEX"
   },
   "source": [
    "### Create and prepare the training dataset using the DetectorDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9abcd0a46b4186e36eef702b9d3cfcd989b70f51",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the validation dataset\n",
    "dataset_train = DetectorDataset(\n",
    "    image_train_list, image_annotations, \n",
    "    ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52138636b2ae5bf444bba808518cd8313bde65cd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TgpT9AzC2Bgz",
    "outputId": "60f5a175-4666-497d-b4e8-0bdab39a92d0"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(DetectorConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(\n",
    "    mode='inference', \n",
    "    config=inference_config,\n",
    "    model_dir=ROOT_DIR)\n",
    "\n",
    "model.load_weights(\n",
    "    '../input/0155-maskrcnn-for-rsna-pneumonia-challenge/mask_rcnn_pneumonia_0030.h5', \n",
    "    by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e6035e8052f4a2fe5c387995e4f93a13f6fcb86"
   },
   "source": [
    "### Show predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61a540a4c280d01bac53677a07bef771f0edd711",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "InceptionResNetV2 = load_model('../input/inceptionresnetv2-classificator/keras.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bfe97c571921f947c515686127c0e9133c581a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show few example of ground truth vs. predictions on the validation dataset \n",
    "dataset = dataset_val\n",
    "\n",
    "for i in range(50):\n",
    "    image_id = random.choice(np.arange(1000))\n",
    "    \n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "        dataset_train, inference_config, image_id, use_mini_mask=False)\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20,5))\n",
    "    for i, box in enumerate(gt_bbox):\n",
    "        ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "        p = Polygon(((xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)),\n",
    "            fc=(1.0, 0.2, 0.2, 0.35), \n",
    "            ec=(1.0, 0.2, 0.2 ,0.95), lw=3, linestyle='--')\n",
    "        ax[0].add_patch(p)\n",
    "    ax[0].imshow(image)\n",
    "    \n",
    "    results = model.detect([image])[0]\n",
    "    \n",
    "    for i, box in enumerate(results['rois']):    \n",
    "        ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "        \n",
    "        # classification InceptionResNetV2\n",
    "        input_shape = (299,299)\n",
    "        original_image = dataset_train.load_image(image_id)\n",
    "        y_scale = original_image.shape[0] / image.shape[0]\n",
    "        x_scale = original_image.shape[1] / image.shape[1]\n",
    "        ymin *= y_scale; ymax *= y_scale\n",
    "        xmin *= x_scale; xmax *= x_scale\n",
    "        y = int(((ymax-ymin)/2 + ymin) - (input_shape[0]/2))\n",
    "        x = int(((xmax-xmin)/2 + xmin) - (input_shape[1]/2))\n",
    "        if y > original_image.shape[0] - input_shape[0]:\n",
    "            y = original_image.shape[0] - input_shape[0]\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        if x > original_image.shape[1] - input_shape[1]:\n",
    "            x = original_image.shape[1] - input_shape[1]\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        \n",
    "        crop_image = original_image[y:y+input_shape[0], x:x+input_shape[1]]/255\n",
    "        if i < 2:\n",
    "            ax[i+2].imshow(crop_image)\n",
    "        \n",
    "        if InceptionResNetV2.predict_proba(crop_image.reshape(-1,input_shape[0],input_shape[1],3)) > 0.5 :\n",
    "            ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "            p = Polygon(((xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)),\n",
    "                fc=(0.0, 0.5, 0.0, 0.1), \n",
    "                ec=(0.0, 0.5, 0.0 ,0.95), lw=3, linestyle='--')\n",
    "            ax[1].add_patch(p)\n",
    "            image[results['masks'][:,:,i]] = image[results['masks'][:,:,i]] * 0.1\n",
    "        \n",
    "    ax[1].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa10709ff298dd7bc6c8ef396891ab71967f1d4e"
   },
   "source": [
    "### Final steps - Create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d77adb807c2e840c5e60c3b877ef2363debc72f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test images, write out sample submission \n",
    "def predict(image_fps, filepath='submission.csv'): \n",
    "    \n",
    "    # assume square image\n",
    "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        for image_id in tqdm(image_fps): \n",
    "            ds = pydicom.read_file(image_id)\n",
    "            original_image = ds.pixel_array\n",
    "            \n",
    "            # If grayscale. Convert to RGB for consistency.\n",
    "            if len(original_image.shape) != 3 or original_image.shape[2] != 3:\n",
    "                original_image = np.stack((original_image,) * 3, -1) \n",
    "            image, window, scale, padding, crop = utils.resize_image(\n",
    "                original_image,\n",
    "                min_dim=config.IMAGE_MIN_DIM,\n",
    "                min_scale=config.IMAGE_MIN_SCALE,\n",
    "                max_dim=config.IMAGE_MAX_DIM,\n",
    "                mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "            patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "\n",
    "            results = model.detect([image])[0]\n",
    "\n",
    "            out_str = \"\"\n",
    "            out_str += patient_id \n",
    "            out_str += \",\"\n",
    "            assert( len(results['rois']) == len(results['class_ids']) == len(results['scores']) )\n",
    "            if len(results['rois']) == 0: \n",
    "                pass\n",
    "            else: \n",
    "                for i, box in enumerate(results['rois']): \n",
    "                    ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "\n",
    "                    # classification InceptionResNetV2\n",
    "                    input_shape = (299,299,3)\n",
    "                    y_scale = original_image.shape[0] / image.shape[0]\n",
    "                    x_scale = original_image.shape[1] / image.shape[1]\n",
    "                    ymin *= y_scale; ymax *= y_scale\n",
    "                    xmin *= x_scale; xmax *= x_scale\n",
    "                    y = int(((ymax-ymin)/2 + ymin) - (input_shape[0]/2))\n",
    "                    x = int(((xmax-xmin)/2 + xmin) - (input_shape[1]/2))\n",
    "                    if y > original_image.shape[0]:\n",
    "                        y = original_image.shape[0] - input_shape[0]\n",
    "                    if y < 0:\n",
    "                        y = 0\n",
    "                    if x > original_image.shape[1]:\n",
    "                        x = original_image.shape[1] - input_shape[1]\n",
    "                    if x < 0:\n",
    "                        x = 0\n",
    "                        \n",
    "                    crop_image = original_image[y:y+input_shape[0], x:x+input_shape[1]]/255\n",
    "                    \n",
    "                    if crop_image.shape != input_shape:\n",
    "                        if len(crop_image.shape) == 4:\n",
    "                            crop_image = crop_image[0]\n",
    "                        temp = np.zeros((input_shape[0],input_shape[1],input_shape[2]))\n",
    "                        temp[:crop_image.shape[0], :crop_image.shape[1], :crop_image.shape[2]] = crop_image\n",
    "                        crop_image = temp\n",
    "                    crop_image = crop_image[np.newaxis]\n",
    "            \n",
    "                    if InceptionResNetV2.predict_proba(crop_image) > 0.5:\n",
    "                        out_str += ' '\n",
    "                        out_str += str(round(results['scores'][i], 2))\n",
    "                        out_str += ' '\n",
    "\n",
    "                        # x1, y1, width, height \n",
    "                        x1 = results['rois'][i][1]\n",
    "                        y1 = results['rois'][i][0]\n",
    "                        width = results['rois'][i][3] - x1 \n",
    "                        height = results['rois'][i][2] - y1 \n",
    "                        bboxes_str = \"{} {} {} {}\".format(\n",
    "                            x1*resize_factor, y1*resize_factor, \n",
    "                            width*resize_factor, height*resize_factor)   \n",
    "                        out_str += bboxes_str\n",
    "\n",
    "            file.write(out_str+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0846ae0fd86a5fa7599ec62ea55e2b02c2dc6586",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get filenames of test dataset DICOM images\n",
    "test_image_fps = get_dicom_fps(test_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0406e7f5aaa4867782c4f9c064f90bba386128e7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "C5cBpNka2Bsv",
    "outputId": "a2af9176-d9d6-49f6-f22a-5a1c455d144f"
   },
   "outputs": [],
   "source": [
    "submission = os.path.join(ROOT_DIR, 'submission.csv')\n",
    "predict(test_image_fps, filepath=submission)\n",
    "\n",
    "output = pd.read_csv(submission, names=['patientId', 'PredictionString'])\n",
    "output.to_csv('../output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lesson-3-rsna-pneumonia-detection-challenge-kaggle",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
